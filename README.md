# Wikipedia Scraper

A Python-based web scraper to fetch content from Wikipedia pages and save it to a text file.

## Features

- Fetches the main content of any Wikipedia page.
- Automatically generates an output filename based on the input topic.
- Saves the extracted content to a `.txt` file in the project folder.

## Requirements

- Python 3.8+
- Internet connection

## Installation

1. Clone this repository:
    ```bash
    git clone https://github.com/your-username/wiki_scraper.git
    cd wiki_scraper
    ```

2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the scraper:
    ```bash
    python main.py
    ```

## Usage

1. Run the program and enter a topic (e.g., `Python programming language`).
2. The program will generate a filename based on the topic (e.g., `Python_programming_language.txt`) and save the content to that file in the project folder.
3. Example flow:
    ```plaintext
    Enter the Wikipedia topic to scrape: Python programming language
    Generated output file name: /path/to/project/Python_programming_language.txt
    Fetching page...
    Extracting content...
    Content saved to /path/to/project/Python_programming_language.txt
    Process completed successfully!
    ```

## Notes

- The filename is generated by replacing spaces in the topic with underscores and appending `.txt`.
- The content is saved in the same folder as the script.
- This program fetches the main content from the Wikipedia page (excluding tables and images).
- Handle the topic names correctly (e.g., ensure accurate spelling).

## License

This project is licensed under the MIT License.
